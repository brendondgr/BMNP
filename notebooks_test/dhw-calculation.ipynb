{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import configparser as cp\n",
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in successfully\n"
     ]
    }
   ],
   "source": [
    "# Read the configuration file\n",
    "config = cp.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "print('Loaded in successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): lat(35), lon(32), time(3653)\n",
      "    variables(dimensions): float32 lat(lat), float32 lon(lon), int64 time(time), int16 analysed_sst(time, lat, lon)\n",
      "    groups:  <class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    description: Subsetted HRCS Data\n",
      "    source: Subsetted from 1985-2019_data.csv\n",
      "    dimensions(sizes): lat(30), lon(24)\n",
      "    variables(dimensions): float32 lat(lat), float32 lon(lon), float32 variable(lat, lon)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "# Load in data for MUR SST pre 2020\n",
    "path = config['settings']['MUR_pre2020'][1:]\n",
    "path = f'..{path}'\n",
    "\n",
    "# Load in HRCS mmm data\n",
    "path2 = '../data/refined/HRCS_nc/1985-2019_mmm_observed.nc'\n",
    "\n",
    "# Load in mur data\n",
    "mur = nc.Dataset(path)\n",
    "\n",
    "# load in HRCS data\n",
    "hrcs = nc.Dataset(path2)\n",
    "\n",
    "print(mur, hrcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the dimension of the two datasets, the latitude and longitude should be in the same range.\n",
    "# Read the latitude and longitude values from the hrcs dataset\n",
    "hrcs_lat = hrcs.variables['lat'][:]\n",
    "hrcs_lon = hrcs.variables['lon'][:]\n",
    "\n",
    "# Find the min and max of the latitude and longitude values\n",
    "lat_min = hrcs_lat.min()\n",
    "lat_max = hrcs_lat.max()\n",
    "lon_min = hrcs_lon.min()\n",
    "lon_max = hrcs_lon.max()\n",
    "\n",
    "# Read the latitude and longitude values from the mur dataset\n",
    "mur_lat = mur.variables['lat'][:]\n",
    "mur_lon = mur.variables['lon'][:]\n",
    "\n",
    "# Find the indices in the mur dataset that correspond to the hrcs ranges\n",
    "lat_inds = np.where((mur_lat >= lat_min) & (mur_lat <= lat_max))[0]\n",
    "lon_inds = np.where((mur_lon >= lon_min) & (mur_lon <= lon_max))[0]\n",
    "\n",
    "# Use these indices to slice the mur dataset\n",
    "mursst = mur.variables['analysed_sst'][:, lat_inds, lon_inds]\n",
    "\n",
    "# Retrieve a list of the dates from the mur dataset\n",
    "mursstdates = mur.variables['time'][:]\n",
    "\n",
    "mur.close()\n",
    "\n",
    "# Load hrcs to numpy array.\n",
    "hrcs_sst = (hrcs.variables['variable'][:, :])\n",
    "hrcs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 3653, Lat: 30, Lon: 24\n",
      "(30, 24)\n"
     ]
    }
   ],
   "source": [
    "print(f'Time: {mursst.shape[0]}, Lat: {mursst.shape[1]}, Lon: {mursst.shape[2]}')\n",
    "print(hrcs_sst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 <class 'list'>\n",
      "(156, 30, 24) <class 'numpy.ma.core.MaskedArray'>\n",
      "['202001', '202002', '202003', '202004', '202005', '202006', '202007', '202008', '202009', '202010', '202011', '202012', '202101', '202102', '202103', '202104', '202105', '202106', '202107', '202108', '202109', '202110', '202111', '202112', '202201', '202202', '202203', '202204', '202205', '202206', '202207', '202208', '202209', '202210', '202211', '202212', '201001', '201002', '201003', '201004', '201005', '201006', '201007', '201008', '201009', '201010', '201011', '201012', '201101', '201102', '201103', '201104', '201105', '201106', '201107', '201108', '201109', '201110', '201111', '201112', '201201', '201202', '201203', '201204', '201205', '201206', '201207', '201208', '201209', '201210', '201211', '201212', '201301', '201302', '201303', '201304', '201305', '201306', '201307', '201308', '201309', '201310', '201311', '201312', '201401', '201402', '201403', '201404', '201405', '201406', '201407', '201408', '201409', '201410', '201411', '201412', '201501', '201502', '201503', '201504', '201505', '201506', '201507', '201508', '201509', '201510', '201511', '201512', '201601', '201602', '201603', '201604', '201605', '201606', '201607', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705', '201706', '201707', '201708', '201709', '201710', '201711', '201712', '201801', '201802', '201803', '201804', '201805', '201806', '201807', '201808', '201809', '201810', '201811', '201812', '201901', '201902', '201903', '201904', '201905', '201906', '201907', '201908', '201909', '201910', '201911', '201912']\n"
     ]
    }
   ],
   "source": [
    "# Load mur mmm nc file\n",
    "path3 = '../data/refined/mur_mmm.nc'\n",
    "mur_mmm = nc.Dataset(path3)\n",
    "\n",
    "# Match the dimension of the two datasets, the latitude and longitude should be in the same range.\n",
    "lat_inds = np.where((mur_mmm['lat'][:] >= lat_min) & (mur_mmm['lat'][:] <= lat_max))[0]\n",
    "lon_inds = np.where((mur_mmm['lon'][:] >= lon_min) & (mur_mmm['lon'][:] <= lon_max))[0]\n",
    "calculatedmmmsst = mur_mmm['mmm_sst'][:, lat_inds, lon_inds]\n",
    "\n",
    "# Retrieve a list of labels for the time dimension\n",
    "calculatedmmmssttime = mur_mmm['time'][:]\n",
    "\n",
    "# Convert to list\n",
    "calculatedmmmssttime = calculatedmmmssttime.tolist()\n",
    "\n",
    "# Convert every item to an int\n",
    "calculatedmmmssttime = [str(int(i)) for i in calculatedmmmssttime]\n",
    "\n",
    "# Close\n",
    "mur_mmm.close()\n",
    "\n",
    "print(len(calculatedmmmssttime), type(calculatedmmmssttime))\n",
    "print(calculatedmmmsst.shape, type(calculatedmmmsst))\n",
    "print(calculatedmmmssttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the datetime module\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.00313\n"
     ]
    }
   ],
   "source": [
    "# For loop going through each 'time' step in mursst\n",
    "number = 0\n",
    "\n",
    "# delete all items in ./data/\n",
    "for root, dirs, files in os.walk('./testfolder/'):\n",
    "    for file in files:\n",
    "        os.remove(os.path.join(root, file))\n",
    "\n",
    "    \n",
    "# Load the hrcs data\n",
    "locationhrcs = '../data/refined/HRCS_nc/1985-2019_mmm_observed.nc'\n",
    "hrcs = nc.Dataset(locationhrcs).variables['variable'][:] - 0.4\n",
    "\n",
    "# bleaching threshold is hrcs plus one\n",
    "bleachingthreshold = hrcs + 1\n",
    "\n",
    "# Find the bleaching threshold average for the entire dataset. Mean should be found using non-nan values.\n",
    "averagebleachingthreshold = np.nanmean(bleachingthreshold)\n",
    "print(averagebleachingthreshold)\n",
    "\n",
    "for day in range(83, mursst.shape[0]):\n",
    "    # Initialize countsim\n",
    "    contsim = True\n",
    "    \n",
    "    # Make numpy array for weekly heat stress\n",
    "    totalheatstress = np.zeros((mursst.shape[1], mursst.shape[2]))\n",
    "    \n",
    "    # Read in the date from mursst\n",
    "    date = datetime.datetime(2002, 6, 1) + datetime.timedelta(days=int(mursstdates[day]))\n",
    "    \n",
    "    # Convert date to string, with only year and month\n",
    "    dateymd = date.strftime('%Y%m%d')\n",
    "    \n",
    "    \n",
    "    for i in range(84):\n",
    "        # Check to see if day-84 is less than 0, skip and set contsim to false. otherwise create dailyheatstress\n",
    "        if day - 84 < 0:\n",
    "            contsim = False\n",
    "            break\n",
    "        else:\n",
    "            dailyheatstress = ((mursst[day - i, :, :] - 273.14) - bleachingthreshold)\n",
    "            #print(dailyheatstress)\n",
    "        \n",
    "        # Replace any values that are below 1 in dailyheatstress with 0\n",
    "        dailyheatstress[dailyheatstress < 0] = 0\n",
    "        \n",
    "        # Add dailyheatstress to totalheatstress\n",
    "        totalheatstress += dailyheatstress\n",
    "        \n",
    "    if contsim:\n",
    "        totalheatstress = (totalheatstress/7).round(2)\n",
    "        # convert totalheatstress to a dataframe\n",
    "        totalheatstress = pd.DataFrame(totalheatstress)\n",
    "        \n",
    "        # save as csv in ./data/{dateym}.csv\n",
    "        totalheatstress.to_csv(f'./testfolder/{dateymd}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all items in ./data/\n",
    "for root, dirs, files in os.walk('./tempdata/'):\n",
    "    for file in files:\n",
    "        os.remove(os.path.join(root, file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
